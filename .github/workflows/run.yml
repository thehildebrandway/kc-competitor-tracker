name: Weekly IG Competitor Tracker (Apify, per-handle)

on:
  workflow_dispatch:        # manual button
  schedule:
    - cron: "0 16 * * 1"    # Mondays 08:00 PT

permissions:
  contents: write

jobs:
  run-tracker:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          persist-credentials: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          pip install pandas python-dateutil pytz requests

      - name: Scrape with Apify and build CSV (per-handle, proxy on)
        env:
          APIFY_TOKEN: ${{ secrets.APIFY_TOKEN }}
        run: |
          python - << 'PY'
          import os, json, time, requests, pandas as pd
          from datetime import datetime

          token = os.environ.get("APIFY_TOKEN", "").strip()
          if not token:
              raise SystemExit("Missing APIFY_TOKEN secret. Add it in Settings → Secrets → Actions.")

          # read usernames one per line, no @
          handles = [h.strip().lstrip("@") for h in open("competitors.csv") if h.strip()]

          ACTOR = "apify~instagram-scraper"
          RUN_URL = f"https://api.apify.com/v2/acts/{ACTOR}/run-sync-get-dataset-items"
          HEADERS = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}

          def ts_to_iso(it):
              for k in ("timestamp","takenAtTimestamp","taken_at_timestamp"):
                  v = it.get(k)
                  if isinstance(v, (int, float)):
                      return datetime.utcfromtimestamp(v).strftime("%Y-%m-%dT%H:%M:%SZ")
                  if isinstance(v, str):
                      try:
                          return datetime.fromisoformat(v.replace("Z","+00:00")).strftime("%Y-%m-%dT%H:%M:%SZ")
                      except Exception:
                          pass
              return ""

          all_rows = []
          for uname in handles:
              payload = {
                  "usernames": [uname],           # one handle per run to avoid batch quirks
                  "resultsType": "posts",
                  "resultsLimit": 120,
                  "includeCommentCount": True,
                  "includeLikeCount": True,
                  "includeCaption": True,
                  "scrollWaitSecs": 1,
                  "proxy": {"useApifyProxy": True}
              }
              try:
                  r = requests.post(RUN_URL, headers=HEADERS, json=payload, timeout=600)
                  if r.status_code == 401:
                      raise SystemExit("Apify 401 Unauthorized: APIFY_TOKEN invalid/expired.")
                  r.raise_for_status()
                  items = r.json() or []
                  print(f"[INFO] {uname}: {len(items)} items")
              except Exception as e:
                  print(f"[WARN] {uname}: request failed ({e})")
                  items = []

              for it in items:
                  t = (it.get("type") or "").lower()
                  if t not in ("post","reel","carousel"):
                      continue
                  caption = (it.get("caption") or "").replace("\n"," ").strip()
                  likes = int(it.get("likesCount") or 0)
                  comments = int(it.get("commentsCount") or 0)
                  followers = int(it.get("ownerFollowersCount") or 0)
                  images_count = int(it.get("imagesCount") or 0)
                  is_video = bool(it.get("isVideo"))
                  ptype = "reel" if is_video else ("carousel" if images_count > 1 else "image")
                  all_rows.append({
                      "platform": "instagram",
                      "profile": f"@{uname}",
                      "post_url": it.get("url") or "",
                      "published_at": ts_to_iso(it),
                      "type": ptype,
                      "caption": caption[:500],
                      "hook_text": " ".join(caption.split()[:10]),
                      "likes": likes,
                      "comments": comments,
                      "followers_snapshot": followers,
                      "est_engagement_rate": round((likes+comments)/followers, 4) if followers else 0.0
                  })

              time.sleep(2)  # be nice to API

          cols = ["platform","profile","post_url","published_at","type","caption","hook_text","likes","comments","followers_snapshot","est_engagement_rate"]
          df = pd.DataFrame(all_rows, columns=cols)

          if not df.empty and df["published_at"].fillna("").ne("").any():
              df = df.sort_values("published_at", ascending=False, na_position="last")

          if df.empty:
              df.loc[0] = ["instagram","","","","","","NO DATA RETURNED",0,0,0,0.0]

          df.to_csv("posts_raw.csv", index=False)
          print(f"[DONE] Wrote {len(df)} rows to posts_raw.csv")
          PY

      - name: Commit CSV to repo
        run: |
          git config user.name "github-actions"
          git config user.email "actions@github.com"
          git add posts_raw.csv
          git commit -m "chore: update posts_raw.csv [skip ci]" || echo "No changes to commit"
          git push
